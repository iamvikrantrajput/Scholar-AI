{
  "texts": [
    "Introduction to Linear Optimization Lecture 1 Martin B ohm University of Wroc law, Spring 2025 D(Linear program): A linear program is a model of an optimization problem over real-valued variables using linear constraints and a linear objective function. A linear function: c1 x1 + c2 x2 + c3 x3 + + cnxn. ci are constants, xi are variables. A linear constraint: c1x1 + c2x2 + + cnxn b. b is a right- hand-side constant. Typical LP: min c1x1 +c2x2+ . . . +cnxn s.t. a1,1x1 +a1,2x2+ . . . +a1,nxn b1 a2,1x1 +a2,2x2+ . . . +a2,nxn b2 . . . am,1x1+am,2x2+. . . +am,nxn bm i: xi 0, xi R Compact form: min cT x s.t. Ax b x 0 T: An optimal vector x to a linear program can be computed in polynomial time with respect to the program size. Notes: We can use any linear inequalities we want , and =. We can use maximum instead of minimum. If our model has no feasible solution, the solver will inform us about this also in polynomial time. We can also detect unboundedness in polynomial time. Five reasons why I love linear programming 1. Linear programs of polynomial size are efficiently solvable they have a polynomial bound in the worst-case, and they have very fast practical algorithms (called solvers) which are publicly available and significantly faster than the worst-case bounds on most real-world instances. 2. Linear programming proved extremely useful in practice throughout the 20th and 21st century, with a Nobel prize in economics being awarded to the field as well as being a crucial model for planning, routing and scheduling to this day. Personal anecdote: While I was in Germany in 2018, my group was actively collaborating with the steel-mill industry where linear programming was used to optimize time and re- sources. 3. A modeling tool: If you can describe it, it is solvable. In classical Algorithm courses, it is sometimes easy to describe a problem but then its complexity is difficult or even impossible to resolve. Linear programming is P-complete (see below) and thus there is no way to state a hard problem at all. (Of course, a transfor- mation from a problem in P to its linear program may not be obvious.) 4. Every solution comes with a certificate. In other words, once an optimum solution is found, the complexity of verifying its optimality is equivalent to verifying a specific set of linear in- equalities, which can be done very efficiently. 5. Linear programming has seen extensive use in approximation algorithms. Approximation algorithms is a field which designs polynomial time algorithms that solve an optimization problem (whose decision version is NP-complete), but return a solution that is at most c-times worse, where c is a small value common values are 2 or 1 + ε. Linear programming and complexity theory T: If a linear program is bounded and has at least one feasible solu- tion, it always has an optimal solution. P: The proof comes later in the semester. D(Integer linear program): An integer linear program is an optimiza- tion problem over integer variables using linear constraints and a lin- ear objective function. Compact form: min cT x s.t. Ax b x 0, x N We also talk about mixed integer linear programming (MILP) when some variables are real-valued, and some variables are integer-valued. This is quite common in real-world usage. T: Consider the decision problem where we get on input a polynomial- sized integer program and the task is to decide whether it has at least one feasible solution. This problem is NP-complete. Recall the definition of NP-completeness: D(NP): A decision problem belongs to the class NP if it can be verified in polynomial time there exists a polynomial-time algorithm that answers Yes when given the decision problem instance and a correct solution, and will answer No on any incorrect solution. D(NP-hard): A decision problem π is NP-hard if all problems in NP can be transformed to π using a polynomial time algorithm called a reduction. In other words, this problem π is at least as hard as any problem that belongs to NP. D(NP-complete): A decision problem is NP-complete if it simultane- ously belongs to NP and is NP-hard. Linear programming has a similar completeness property: D(P): A decision problem belongs to the class P if it can be decided by an algorithm in polynomial time. D(L/LOGSPACE): A decision problem belongs to the class L if it can be decided by an algorithm whose writable memory is at most logarithmic in the size of the input. D(P-hard, P-complete): A decision problem π is P-hard if all prob- lems in P can be reduced to it using a reduction algorithm that is in L. A problem π is P-complete if it lies in P and is P-hard. T: Deciding whether a given linear program has at least one feasible solution is P-complete. Modeling with LPs There is no correct way to model a problem with a linear program. In fact, many problems have several useful LP formulations. There is no guarantee that a nice (readable, reasonable, etc.) model even exists. Useful questions at the beginning: 1. Q: What should our variables x be? 2. Q: How should we model the objective function? A numerical problem max x2 s.t. x2 2 + x1 x2 4 1 2 x1 xi 0 i {1, 2} 0 1 2 3 4 0 1 2 3 4 x2 2 + x1 x2 4 1 2 x1 Line fitting Task: Given a collection of two-dimensional data points, find a straight line that best approximates the data.",
    "Some possible objectives: Least Squares Method/squared L2 norm: min Pn i=1(axi + b yi)2. Computable, but not easily with linear programming. Minimizing L1 norm: min Pn i=1 axi + b yi . Minimizing the L1 norm: min n X i=1 ei s.t. i {1, . . . , n}: ei axi + b yi i {1, . . . , n}: ei (axi + b yi) a R, b R, i: ei 0. Flows in networks Problem Maximum Flow: Input: An edge-weighted, directed graph G = (V, E, c) (a network). Every directed edge has an associated capacity ce 0. Addi- tionally, there are two special vertices source s and sink t. Output: Any flow function f : E R+ 0 which obeys capacities (f(e) ce) and follows Kirchhoff s law in every non-special vertex, fluid coming in = fluid coming out. Goal: Find a flow that sends as much fluid as possible from s to t. max X si x si s.t. ij E(G): x ij c ij v V (G) {s, t}: X vi x vi X jv x jv = 0 ij E(G): x ij 0, x ij R T: Maximum Flow is solvable in polynomial time. Exercises Exercise one. Formulate the following as a linear program. Use graphical methods (or guesswork) to find the optimal solution. Ingredients: Pizza Lasagne available Tomatoes 2 3 18 Cheese 4 3 24 Profit: Pizza 16 PLN, Lasagne 14 PLN Task: Determine optimal producible number of pizza and lasagne to maximize total profit. Exercise two. Given a graph with directed edges, weights on the edges and two special vertices s and t, we say a cut is any collection of edges S E whose removal disconnects all directed paths from s to t. Naturally, since E is a valid cut, we look for the cut with minimum to- tal weight. Using simple logical arguments, can you find the minimum cut on the following directed graph from the lecture? 5 7 6 3 4 2 2 5 2 1 3 1 1 1 2 2 5 s t Exercise three. Suppose we have a real matrix A and appropriate vectors b, c. From those, we can build the following integer program C: max cT x Ax b x {0, 1}n Using the same givens, we could also build a linear program L: max cT x Ax b x [0, 1]n Assume that both programs have a solution. Suppose that we pick one optimal solution of the integer program and call it x C, and we also pick one optimal solution of the linear program, denoting it x L. Prove the following inequality: cT x C cT x L. Exercise four. Let us consider the following NP-hard problem, called Weighted Vertex Cover: Input: Undirected graph G with non-negative real weights on the vertices, given by a weight function w : V (G) R+ 0 . Goal: To find a subset S of vertices such that each edge e E(G) has at least one endpoint in S. (We say that a vertex covers an edge, so if we cover all edges, we get a vertex cover.) From all such subsets S we look for the one with minimum weight , i.e. minimum P s S w(s). Suggest an integer program with variables x {0, 1} that finds the optimal solution of Weighted Vertex Cover.",
    "Intro to LO, Lecture 3 Martin B ohm University of Wroc law, Spring 2025 Concepts from metric spaces All of the definitions below work for general topological spaces, but we are only interested in the Euclidean space Rn. D(Open set): A set S Rn is called open if for each point p S, there exists a radius r such that all points from a ball B(p, r) are present in S. D(Closed set): A set S is closed if its complement (Rn S) is open. D(Bounded set): A set S is bounded if S fits into a ball of some finite diameter d. D(Compact set): A set S is compact if it is closed and bounded. T: Consider a function f : Rn R. If S is a compact set and f is continuous on S, then there exists points in S where f attains its infimum and supremum value over S. Concepts from linear algebra D: A set A Rd is an affine space, if A is of the form L + v for some linear space L and a shift vector v Rd. By A is of the form L + v we mean a bijection between vectors of L and vectors of A given as b(u) = u + v. Each affine space has a dimension, defined as the dimension of its associated linear space L. D: A vector x is an affine combination of a finite set of vectors a1, a2, . . . , an if x = Pn i=1 αiai, where αi are real number satisfy- ing Pn i=1 αi = 1. A set of vectors V Rd is affinely independent if it holds that no vector v V is an affine combination of the rest. C: A set of vectors {v1, . . . , vn} Rd is affinely dependent if there exists a not-all-zero set of coefficients αi such that P i αivi = 0 and P i αi = 0. O: A set of vectors {v0, v1, . . . , vn} is affinely indepedent if and only if the set {v1 v0, . . . , vn v0} is linearly independent. D: Given a set of vectors V Rd, we can think of its affine span/affine hull, which is a set of vectors A that are all possible affine combina- tions of any finite subset of V Similar to the linear spaces, affine spaces have a finite basis, so we do not need to consider all finite subsets of V , but we can generate the affine span as affine combinations of the base. D(Dimension): The dimension of a set X Rn, X = is the dimen- sion of the affine span of X. O: The dimension of the set X = is the maximal d such that in X there exist affine independent points a0, . . . , ad. T: Every linear space of dimension k contains a basis of k vectors. We can find a special basis that is orthogonal or even orthonormal. And for any basis (even a non-orthogonal one) we can compute its orthogonal complement. (How?) Convexity D: A set K Rd is a convex set, if x, y K, t [0, 1] : tx+(1 t)y K. In other words, if you take two points inside the convex set K, the entire line segment between those two points must belong to K. D: A vector x is a convex combination of a set of vectors a1, a2, . . . , an if x = Pn i=1 αiai, where αi are real numbers satisfying Pn i=1 αi = 1 and also i : αi [0, 1]. A set of vectors/points V Rd is in a convex position, if it holds that no vector v V is a convex combination of the rest. O: Let Y be the set of convex combinations of points from X. Then every convex combination of points of Y is a convex combination of points of X. O: If all points x X satisfy the inequality aT x b, then any convex combination of points from X satisfies this inequality. D: As with linearity and affinity, for convexity we also define a span/hull: If we have a set of vectors V Rd, its convex hull is a set of all vectors C, which are convex combinations of any finite subset of the vectors in V . Here, we really need to consider any finite subset of V , because convex sets in general do not have a finite basis. An alternative (but as we will soon see equivalent) definition: D: For a set of points V Rd, the convex hull, denoted by conv(V ), is the intersection of all (likely infinitely many) convex sets that contain V . These two definitions are equivalent: L: The intersection of all convex sets containing V is equivalent to Y , the set of all convex combinations of finitely many points from V : Y = ( α0a0 + . . . + αkak k N, ai V, αi 0, k X i=0 αi = 1 ) . P: We prove, by induction on d, that all points generated with a con- vex combination from V lie in any convex set containing V , and thus in the intersection of all of them as well. In the second step, we prove that Y is convex itself, and so it is one of the sets intersecting to form the convex hull. Caratheodory s theorem tells us that for objects of dimension d, only combinations of size d + 1 are needed (but d + 1 points from X may not suffice). T(Caratheodory): Let X Rn, dim(X) = d. Then, conv(X) = ( α0a0 + . . . + αdad ai X, αi 0, d X i=0 αi = 1 ) . P: We proceed by induction over the dimension d, showing that for a point x conv(X), any combination of d+2 or more points in Rd",
    "are equivalent: L: The intersection of all convex sets containing V is equivalent to Y , the set of all convex combinations of finitely many points from V : Y = ( α0a0 + . . . + αkak k N, ai V, αi 0, k X i=0 αi = 1 ) . P: We prove, by induction on d, that all points generated with a con- vex combination from V lie in any convex set containing V , and thus in the intersection of all of them as well. In the second step, we prove that Y is convex itself, and so it is one of the sets intersecting to form the convex hull. Caratheodory s theorem tells us that for objects of dimension d, only combinations of size d + 1 are needed (but d + 1 points from X may not suffice). T(Caratheodory): Let X Rn, dim(X) = d. Then, conv(X) = ( α0a0 + . . . + αdad ai X, αi 0, d X i=0 αi = 1 ) . P: We proceed by induction over the dimension d, showing that for a point x conv(X), any combination of d+2 or more points in Rd can be reduced to a smaller set. For d = 1, any convex combination of at least 3 points on the real line can be reduced to just two endpoints. It is easy to see that for any d we can just focus on convex combina- tions of exactly d + 2 points, as we can subselect d + 2 points from a larger set and use the theorem. For d 1, we wish to remove one point from the representation x = d+1 X i=0 αiai. First, consider the initial d+1 points in the combination a0, a1, . . . , ad. If they are affinely dependent, their dimension is also smaller, and so we can use induction to remove one of them from their convex com- bination. If they are affinely independent, we can express the last vector ad+1 = Pd i=0 βiai for a vector β in Rd, P i βi = 1. We now fo- cus on a point x conv(X). We have a sequence of representations parametrized by θ [0, 1]: x = d X i=0 (αi + θαd+1βi)ai + (1 θ)αd+1ad+1. Notice that for θ = 0 this is the original representation of x, and for θ = 1 we have fully integrated the coefficients of ad+1 using the affine combination. Now, if all coefficients (αi + αd+1βi) are non-negative, we are done as we can just set θ = 1. Suppose one of them is negative. We know that for θ = 0, all the coefficients of the form (αi + θαd+1βi) are non-negative (they have the original value αi). So, if we continuously move from θ = 1 to θ = 0, at some point the last of the negative ones will become zero. When it becomes zero, the associated point no longer contributes to the convex combination, and the remaining ones are non-negative, so we can reduce the size of the set. D: A hyperplane is any affine space in Rd of dimension d 1. Thus, on a 2D plane, any line is a hyperplane. In the 3D space, any plane is a hyperplane, and so on. A hyperplane splits the space Rd into two halfspaces. We count the hyperplane itself as a part of both halfspaces. D: A convex polyhedron (sometimes also called H-polytope) is any object in Rd that is an intersection of finitely many halfspaces. Al- ternatively, we can say that a convex polytope is any set of points of the form {x Ax b} for some real matrix A and some real vector b. T(Separation theorem): Let C, D Rn be nonempty, closed, con- vex and disjoint. and let C be bounded. Then there is a hyper- plane x aT x = b , which strongly separates C and D, i.e., one that C x aT x b a D x aT x b . Exercises Exercise one. 1. Can two 2D planes intersect in exactly one point, if we place them in R4? 2. Can two 3D spaces (affine subspaces of dimension 3) intersect in exactly one point in R5?",
    "Exercise two. You might recall the definition of convexity for func- tions: D(Convexity of a function): A function f : Rn R is convex if for any t [0, 1] and any two points x, y we have f(tx + (1 t)y) tf(x) + (1 t)f(y). Let us define the epigraph as points above the curve of the function , formally: epif Rn+1; epif = {(x, v) Rn+1 v f(x)}. Prove that a function f is convex if and only if its epigraph is a convex set. Exercise three. Prove the following: Let C Rn. Then, C is a closed convex set if and only if it can be expressed as C = T F F F for some family of halfspaces F. (A family here means just a set, not necessarily finite.) Hints: One thing that might be useful here is that an arbitrary, even infinite, intersection of closed sets is again a closed set. Another thing that might be useful is some theorem from the lecture.",
    "Intro to LO, Lecture 4 Martin B ohm University of Wroc law, Spring 2025 Refresh: Concepts from metric spaces All of the definitions below work for general topological spaces, but we are only interested in the Euclidean space Rn. D(Open set): A set S Rn is called open if for each point p S, there exists a radius r such that all points from a ball B(p, r) are present in S. D(Closed set): A set S is closed if its complement (Rn S) is open. D(Bounded set): A set S is bounded if S fits into a ball of some finite diameter d. D(Compact set): A set S is compact if it is closed and bounded. T: Consider a function f : Rn R. If S is a compact set and f is continuous on S, then there exists points in S where f attains its infimum and supremum value over S. Refresh: Convexity D: A set K Rd is a convex set, if x, y K, t [0, 1] : tx+(1 t)y K. In other words, if you take two points inside the convex set K, the entire line segment between those two points must belong to K. D: A vector x is a convex combination of a set of vectors a1, a2, . . . , an if x = Pn i=1 αiai, where αi are real numbers satisfying Pn i=1 αi = 1 and also i : αi [0, 1]. A set of vectors/points V Rd is in a convex position, if it holds that no vector v V is a convex combination of the rest. O: Let Y be the set of convex combinations of points from X. Then every convex combination of points of Y is a convex combination of points of X. O: If all points x X satisfy the inequality aT x b, then any convex combination of points from X satisfies this inequality. D: As with linearity and affinity, for convexity we also define a span/hull: If we have a set of vectors V Rd, its convex hull is a set of all vectors C, which are convex combinations of any finite subset of the vectors in V . Here, we really need to consider any finite subset of V , because convex sets in general do not have a finite basis. An alternative definition: D: For a set of points V Rd, the convex hull, denoted by conv(V ), is the intersection of all (likely infinitely many) convex sets that contain V . These two definitions are equivalent: L: The intersection of all convex sets containing V is equivalent to Y , the set of all convex combinations of finitely many points from V : Y = ( α0a0 + . . . + αkak k N, ai V, αi 0, k X i=0 αi = 1 ) . D: A hyperplane is any affine space in Rd of dimension d 1. Thus, on a 2D plane, any line is a hyperplane. In the 3D space, any plane is a hyperplane, and so on. A hyperplane splits the space Rd into two halfspaces. We count the hyperplane itself as a part of both halfspaces. A hyperplane is specified by a normal vector a and a bias b. The hyperplane is then defined as the set of points x for which aT x = b. Similarly, a halfspace has a normal description {x aT x b}. D: A convex polyhedron (sometimes also called H-polytope) is any object in Rd that is an intersection of finitely many halfspaces. Alter- natively, we can say that a convex polytope is any set of points of the form {x Ax b} for some real matrix A and some real vector b. Separation theorem T(Separation theorem): Let C, D Rn be nonempty, closed, con- vex and disjoint. and let C be bounded. Then there is a hyper- plane x aT x = b , which strongly separates C and D, i.e., one that C x aT x b a D x aT x b . Proof steps. 1. If both C D are bounded, they are also compact and so is the product C D R2n, and since the Euclidean norm is continuous, we can find minimizers c C and d D. 2. If D is unbounded, we restrict ourselves to a set D D that is bounded as follows: Let the max distance in C be α. We sample one c C and d D and let their distance be β. Now, restrict D to D = D B(c , α + β). A simple observation shows that all points in D that have a chance to be closer than β to C live in D . 3. Find the closest points in C and D, call them c, d, respectively. Let a = d c be the direction between them. The separating hyperplane will be orthogonal to c d and will touch the point (c + d)/2. 4. aT d aT c = P i d2 i 2dici + c2 i = a 2 0. Strict because c = d. 5. If the difference of two numbers is a non-negative real, then their average is strictly between them, in other words: if b = aT (c + d)/2, then aT c b aT d. 6. Finally, we observe that for all other points c C holds that aT c aT c. We observe this geometrically, using the following observations: O(From high school): Consider the angle ϕ at c for the triangle c cd. Then, (d c)T (c c) = d c c c cos ϕ. Since the two norms are always non-negative, the sign of the scalar product depends only on cos ϕ. In particular, if ϕ is acute, the scalar product is positive, if it is obtuse, the scalar product is negative, and if it is a right angle, the scalar product is zero. O: Consider a circle centered at d and a",
    "D, call them c, d, respectively. Let a = d c be the direction between them. The separating hyperplane will be orthogonal to c d and will touch the point (c + d)/2. 4. aT d aT c = P i d2 i 2dici + c2 i = a 2 0. Strict because c = d. 5. If the difference of two numbers is a non-negative real, then their average is strictly between them, in other words: if b = aT (c + d)/2, then aT c b aT d. 6. Finally, we observe that for all other points c C holds that aT c aT c. We observe this geometrically, using the following observations: O(From high school): Consider the angle ϕ at c for the triangle c cd. Then, (d c)T (c c) = d c c c cos ϕ. Since the two norms are always non-negative, the sign of the scalar product depends only on cos ϕ. In particular, if ϕ is acute, the scalar product is positive, if it is obtuse, the scalar product is negative, and if it is a right angle, the scalar product is zero. O: Consider a circle centered at d and a point c on the perimeter of the circle. Suppose we have another point c for which it must hold that no point on the line segment cc is strictly inside the circle. Then, angle at c for the triangle c cd must be obtuse or right. Vertices and basic feasible solutions D(Polyhedron): A set of points is called a polyhedron (or an H- polytope) if it the set is the intersection of finitely many halfspaces. D(Polytope): A set of points is called a polytope (or a V -polytope) if it is a convex hull of a finite number of points. D(Vertex): Let P be a convex set. A point z P is a vertex if z cannot be written as a convex combination of any other two points in P. D(Basic feasible solution): Let P = {x Ax b} Rn be a poly- hedron and let z P. Then Az is the submatrix of A consisting of those rows ai of A for which aiz = bi. We say a point z P is an basic feasible solution if rank (Az) = n. T: Let P = {x Ax b} be a polyhedron in Rn and let z P. Then z is a vertex of P if and only if z is a basic feasible solution. P(From Schrijver): We prove two counterpositive implications: If Az is not full rank, then z is not a vertex ( ). Second, if z is not a vertex, then Az is not full rank ( ). : Az not full rank find c : Azc = 0. z is then a conv. combination of z + δc, z δc for some δ 0. We can find this δ since every equation outside Az held with a strict inequality, so even though c might be the direction where the inequal- ity breaks eventually, it will hold at least for some small δ. : If z not a vertex find two points x, y which combine to it; Az(x y) = 0, so x y is a non-zero solution to Azp = 0. A polyhedron is a convex hull of its vertices T: Let P be a bounded polyhedron, with vertices x1, . . . , xt. Then P = conv.hull {x1, . . . , xt}. P(From Schrijver): Clearly conv.hull {x1, . . . , xt} P since x1, . . . , xt belong to P and since P is convex. The reverse inclu- sion amounts to: if z P then z conv.hull {x1, . . . , xt} . Geometrically, the proof is as follows: we start with z and move in two opposite directions until we hit a face of P. This face is lower- dimensional than P, so we can by induction prove that the two points that we hit with our process are both in the convex hull of the vertices of P, and z is clearly a convex combination of the two points. Formally, we prove it by induction on n rank (Az). Informally, we take a point z P and we find two points in P of higher rank of Az which have z within their line segment. To find these, we take z and move in opposite directions until we reach the boundary of P, since the boundary points will satisfy more equalities than z. Formally, we find the respective increases µ0 := max{µ z + µc P}, ν0 := max{ν z νc P}. And define x := z + µ0c and y := z ν0c to be the two boundary points. For the computation, we need to observe a form of duality : For the µ0 defined above, we have",
    "µ0 = min bi aiz aic ai is a row of A; aic 0 . This follows from the fact that if we maintain ai(z + µc) bi, then µ (bi aiz)/(aic). If the minimum for µ0 is attained at i0, we check that 1. Azx = Azz + µ0Azc = Azz. 2. ai0x = ai0z + µ0ai0c = bi0. So, the rank of Ax, which is the matrix of tight inequalities at the point x = z + µ0c, is at least one higher than the rank of Az. We can apply our induction claim and express x as a convex combination of vertices of P. We proceed analogously for y. C: Every bounded polyhedron is a polytope. T(Without proof): Every polytope is a bounded polyhedron. Exercises Exercise one. Find all the vertices of the following polytope: P = {(x, y, z) x + y 2, y + z 4, x + z 3, 2x y 3, y 2z 3, 2x z 2}. Exercise two. Check if the point v = (1, 1, 1, 1) is a vertex of a polytope P defined as the following set of inequalities: 1 6 1 3 1 2 7 1 0 3 10 1 6 11 2 12 1 6 1 3 x1 x2 x3 x4 3 5 8 7 4 The next two exercises deal with convex cones. Citing from Schrijver s lecture notes: Convex cones are special cases of convex sets. A subset C of Rn is called a convex cone if for any x, y C and any λ, µ 0 one has λx + µy C. For any X Rn, cone (X) is the smallest cone containing X. One easily checks: cone(X) = {λ1x1 + λtxt x1, . . . , xt X; λ1, . . . , λt 0} Exercise three. Let C Rn. Then C is a closed convex cone if and only if C = T F for some collection F of linear halfspaces. (Notice the halfspaces are linear, i.e., going through 0.) Exercise four. For any subset X of Rn, define X := n y Rn xT y 1 for each x X o 1. Show that for each convex cone C, C is a closed convex cone. 2. Show that for each closed convex cone C, (C ) = C.",
    "Intro to LO, Lecture 2 Martin B ohm University of Wroc law, Spring 2025 D(Linear program): A linear program is a model of an optimization problem over real-valued variables using linear constraints and a linear objective function. Compact form: min cT x s.t. Ax b x 0 T: An optimal vector x to a linear program can be computed in polynomial time with respect to the program size. A bakery example A bakery produces four things: bread, bagels, baguettes and donuts. To bake a single bread, they need 500g of flour, 10 eggs and 50 grams of salt. To bake a bagel, they need 150 grams of flour, 2 eggs and 10g of salt. For a baguette, they need 230g of flour, 7 eggs and 15g of salt. For a donut, they need 100g of flour and 1 egg. The bakery has a daily supply of 5 kg of flour, 125 eggs, and 500g of salt. The bakery charges 5 PLN for one bread, 1 PLN for a bagel, 2.5 PLN for a baguette and 1.5 PLN for a donut. The bakery tries to maximize its profit. max 5xch + 1xo + 2.5xb + 1.5xd 500xch + 150xo + 230xb + 100xd 5000 // flour 10xch + 2xo + 7xb + xd 125 // eggs 50xch + 10xo + 15xb 500 // salt xch, xo, xb, xd 0. For a quick online solver, we can use for example https://cocoto. github.io/glpk-online/. A functional GNU MathProg code is: var c = 0; var o = 0; var b = 0; var d = 0; maximize obj: 5*c + 1*o + 2.5*b + 1.5*d; fl: 500*c + 150*o + 230*b + 100*d = 5000; eggs: 10*c + 2*o + 7*b + d = 125; salt: 50*c + 10*o + 15*b = 500; solve; end; From George Dantzig, one of the fathers of linear optimization: I decided to use the simplex method and linear programming to solve a diet problem designed for me to lose weight. Anne agreed she would prepare my meals according to what the computer declared was the optimal diet. (...) So it s getting late in the day and finally Anne calls me up and she says: Well, what s for supper? And I said: Well, we ran the program. A couple of gallons of vinegar and some other stuff were the optimum diet. We ll just gonna have to take vinegar now as our food. Source: https://www.informs.org/Explore/History-of-O.R. -Excellence/Oral-Histories/George-Dantzig. Cutting paper rolls A paper mill manufactures rolls of paper of a standard width 3 me- ters. But customers want to buy paper rolls of shorter width, and the mill has to cut such rolls from the 3 m rolls. One 3 m roll can be cut, for instance, into two rolls 93 cm wide, one roll of width 108 cm, and a rest of 6 cm (which goes to waste). One order could be: 97 rolls of width 135 cm, 610 rolls of width 108 cm, 395 rolls of width 93 cm, and 211 rolls of width 42 cm. What is the smallest number of 3 m rolls that have to be cut in order to satisfy this order, and how should they be cut? The key question for this problem: What should the variables be? We cannot simply have a variable x135 of rolls of width 135 cm, because we know how many we need namely 97 and their number does not help to discover the best partition. With only four types of rolls, there is only a limited number of ways to cut a single 3 m roll. We can call these configurations. For example, we can cut one roll into one 108 cm roll, one 93 cm and two 42 cm rolls, leaving a wasted paper strip of width 15 cm. We plan to have a variable y7 R+ for how many configurations of this type we shall use. Where does this variable appear? If we have an inequality denoting that there are at least 211 rolls of width 42 cm, then it will look like this: + 2y7 + 211. Note the 2 on the left side, as we create 2 rolls of width 42 cm with this configuration. We also create rolls of width 108 cm and 93 cm, so it will appear with coefficient 1 in the corresponding inequalities. It also will appear in the objective, because we wish to minimize the number of rolls used, with coefficient 1. In the end, we have 12 maximal configurations: C1: 2 135 C2: 135 + 108 + 42 C3: 135 + 93 + 42 C4: 135 + 3 42 C5: 2 108 + 2 42 C6: 108 + 2 93 C7: 108 + 93 + 2 42 C8: 108 + 4 42 C9: 3 93 C10: 2 93 + 2 42 C11: 93 + 4 42 C12: 7 42 And the resulting LP is this: min y1 + y2 + . . . + y12 2y1 + y2 + y3 + y4 97 y2 + 2y5 + y6 + y7 + y8 610 y3 + 2y6 + y7 + 3y9 + 2y10 + y11 395 y2 + y3 + 3y4 + 2y5 + 2y7 + 4y8 + 2y10 + 4y11 + 7y12 211 y1, . . . , y12 0 The GNU MathProg code would be: set Configurations := (1..12); var y{i in Configurations}, = 0; minimize obj: sum{i in Configurations} y[i]; cond0: 2*y[1] + y[2] + y[3] + y[4] = 97; cond1: y[2] + 2*y[5] + y[6] + y[7] + y[8] = 610; cond2: y[3] + 2*y[6] + y[7] + 3*y[9] + 2*y[10] + y[11] = 395; cond3: y[2] + y[3] + 3*y[4] + 2*y[5] + 2*y[7] + 4*y[8] + 2*y[10] + 4*y[11] + 7*y[12] = 211; solve; end; Source: From Understanding and Using Linear Programming. Maximum independent set D(Independent set of vertices): For a graph G = (V, E), a set I V of vertices is called independent if no two vertices of I",
    "2 93 + 2 42 C11: 93 + 4 42 C12: 7 42 And the resulting LP is this: min y1 + y2 + . . . + y12 2y1 + y2 + y3 + y4 97 y2 + 2y5 + y6 + y7 + y8 610 y3 + 2y6 + y7 + 3y9 + 2y10 + y11 395 y2 + y3 + 3y4 + 2y5 + 2y7 + 4y8 + 2y10 + 4y11 + 7y12 211 y1, . . . , y12 0 The GNU MathProg code would be: set Configurations := (1..12); var y{i in Configurations}, = 0; minimize obj: sum{i in Configurations} y[i]; cond0: 2*y[1] + y[2] + y[3] + y[4] = 97; cond1: y[2] + 2*y[5] + y[6] + y[7] + y[8] = 610; cond2: y[3] + 2*y[6] + y[7] + 3*y[9] + 2*y[10] + y[11] = 395; cond3: y[2] + y[3] + 3*y[4] + 2*y[5] + 2*y[7] + 4*y[8] + 2*y[10] + 4*y[11] + 7*y[12] = 211; solve; end; Source: From Understanding and Using Linear Programming. Maximum independent set D(Independent set of vertices): For a graph G = (V, E), a set I V of vertices is called independent if no two vertices of I are connected by an edge in G. T: The problem of deciding whether there exists an independent set of size at least k in the graph (or not) is NP-complete. Integer linear program: max X v V xv For each edge {u, v} E : xu + xv 1, For every variable xv : xv {0, 1}.",
    "Shortest path Given s and t in a directed graph G = (V, E), with each edge having a positive distance de associated with it, we wish to find the length of the shortest path from s to t. First LP: Could we model it as a flow problem, with one unit of flow flowing from s to t? If we are allowed an integer linear program, this returns exactly one of the shortest paths: min X uv E duvxuv outflow one from source: X v sv E xsv = 1 Kirchhoff s law: v V {s, t}: X u uv E xuv X w vw E xvw = 0 uv E : xuv {0, 1} Whenever we deal with flows obeying Kirchhoff s law almost every- where, we should be wary of circulations, which might appear in the solution. However, this is not the case here: O: For the optimal solution to the integer LP above, or its linear relaxation with xuv [0, 1], no circulations will occur. We also observe that the length of the shortest path does not change if we consider the linear relaxation, which is an LP and thus solvable in polynomial time: O: The optimal value of the integer LP above and its relaxation with xuv [0, 1] are the same. Second LP: Imagine that instead, we wish to store the length of the shortest path from s to v in each vertex v, much like a Bellman-Ford algorithm would. We would have variables yv in each vertex, and could consider this LP: max yt ys uv E : yv yu duv v V : yv R T: The following linear program has the same optimum value as the length of the shortest path from s to t. Exercises Exercise one. A cargo plane has three compartments for storing cargo: front, center and rear. These compartments have the following limits on both weight and space: Compartment Weight capacity (tons) Space capacity (m3) Front 10 6800 Center 16 8700 Rear 8 5300 Furthermore, the weight of the cargo in the respective compartments must be the same proportion of that compartment s weight capacity to maintain the balance of the plane. The following four cargoes are available for shipment on the next flight: Cargo Weight (tons) Volume (m3/ton) Profit (EUR/ton) C1 18 480 310 C2 15 650 380 C3 23 580 350 C4 12 390 285 Any proportion of these cargos can be accepted. The objective is to determine how much (if any) of each cargo C1, C2, C3 and C4 should be accepted and how to distribute each among the compartments so that the total profit for the flight is maximised. 1. Model this task as a linear program. 2. Write this linear program in the GNU MathProg format and present the optimal solution from the solver in class. Exercise two. Let s make some chocolate! As chocolate is in demand throughout the year, it is important to plan the production properly. The predicted demand according to which we want to plan production is di 0 for the i-th month in tons. Use a linear program to express how much chocolate is to be produced in each month in the following year, so that we always meet demand while spending as little as possible on production. A change in production volume of 1 ton between the following months costs 1500 PLN (due to redundancies or recruitment etc.) and stor- ing 1 ton of chocolate costs 600PLN (counting from one month to the nexth). Don t count the production of the chocolate itself, as it is paid for out of sales. Also assume that the chocolate does not spoil and you should not have any left at the end of December. Hint: Define si as the surplus of chocolate in the ith month, and set s0 = s12 = 0. Exercise three. A classical NP-complete problem is Graph 3- Coloring. It is a decision problem: given a graph G, decide if it its vertices can be colored with three colors such that, if we look at each edge in G, this edge is not monochromatic, thus it sees two colors on its endpoints. Model this problem as an integer linear program. Since this is a deci- sion version, there will be no objective function this is still acceptable for a solver, it will just find any feasible solution."
  ],
  "metadata": [
    {
      "source": "L01.pdf",
      "page": 1,
      "chunk_index": 0,
      "total_chunks_from_page": 1,
      "word_count": 935,
      "processed_at": "2025-07-27T15:21:47.173350",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L01.pdf",
      "page": 2,
      "chunk_index": 0,
      "total_chunks_from_page": 1,
      "word_count": 560,
      "processed_at": "2025-07-27T15:21:47.176163",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L03.pdf",
      "page": 1,
      "chunk_index": 0,
      "total_chunks_from_page": 2,
      "word_count": 1000,
      "processed_at": "2025-07-27T15:21:47.142186",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L03.pdf",
      "page": 1,
      "chunk_index": 1,
      "total_chunks_from_page": 2,
      "word_count": 714,
      "processed_at": "2025-07-27T15:21:47.142218",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L03.pdf",
      "page": 2,
      "chunk_index": 0,
      "total_chunks_from_page": 1,
      "word_count": 168,
      "processed_at": "2025-07-27T15:21:47.143058",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L04.pdf",
      "page": 1,
      "chunk_index": 0,
      "total_chunks_from_page": 2,
      "word_count": 1000,
      "processed_at": "2025-07-27T15:21:47.151341",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L04.pdf",
      "page": 1,
      "chunk_index": 1,
      "total_chunks_from_page": 2,
      "word_count": 814,
      "processed_at": "2025-07-27T15:21:47.151374",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L04.pdf",
      "page": 2,
      "chunk_index": 0,
      "total_chunks_from_page": 1,
      "word_count": 387,
      "processed_at": "2025-07-27T15:21:47.152867",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L02.pdf",
      "page": 1,
      "chunk_index": 0,
      "total_chunks_from_page": 2,
      "word_count": 1000,
      "processed_at": "2025-07-27T15:21:47.163547",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L02.pdf",
      "page": 1,
      "chunk_index": 1,
      "total_chunks_from_page": 2,
      "word_count": 257,
      "processed_at": "2025-07-27T15:21:47.163560",
      "chunk_size": 1000,
      "overlap": 200
    },
    {
      "source": "L02.pdf",
      "page": 2,
      "chunk_index": 0,
      "total_chunks_from_page": 1,
      "word_count": 732,
      "processed_at": "2025-07-27T15:21:47.165931",
      "chunk_size": 1000,
      "overlap": 200
    }
  ],
  "ids": [
    "400ae0f7-225e-4067-b208-c2623581bf89",
    "edd0ef8a-c5af-4088-9ab0-1264e3812cb3",
    "e97cd2c4-caed-493a-9a92-5832e8aaf987",
    "53c1ff8e-867f-4b35-93a4-e6c6b148fcfa",
    "a15add10-8e2d-4688-ad7d-3768773655ad",
    "d3b61856-5777-4bb5-84ed-13db8bce5bc4",
    "9bc7c7e5-15e9-42f5-9a12-a0cae90b7412",
    "4267b837-ada2-4e9a-b2a0-616db6734fb1",
    "23ef1d94-ff17-45aa-a0d4-6e119001e87a",
    "5c784cec-099c-4344-b41a-e0be522d1c6d",
    "7a812a4c-4bd7-4d1e-80db-323bfbd19a98"
  ],
  "dimension": 384,
  "index_type": "IndexFlatIP"
}